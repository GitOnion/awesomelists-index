[
  {
    "name": "[MySQL] (http://www.mysql.com/) The world's most popular open source database.\nPercona XtraBackup Percona XtraBackup is a free, open source, complete online backup solution for all versions of Percona Server, MySQL® and MariaDB®\nmysql_utils Pinterest MySQL Management Tools\n\n",
    "url": "http://www.mysql.com/"
  },
  {
    "name": "Percona XtraBackup Percona XtraBackup is a free, open source, complete online backup solution for all versions of Percona Server, MySQL® and MariaDB®",
    "url": "https://www.percona.com/software/mysql-database/percona-xtrabackup"
  },
  {
    "name": "mysql_utils Pinterest MySQL Management Tools",
    "url": "https://github.com/pinterest/mysql_utils"
  },
  {
    "name": "[MariaDB] (https://mariadb.org/) An enhanced, drop-in replacement for MySQL.",
    "url": "https://mariadb.org/"
  },
  {
    "name": "[PostgreSQL] (http://www.postgresql.org/) The world's most advanced open source database.",
    "url": "http://www.postgresql.org/"
  },
  {
    "name": "[Amazon RDS] (http://aws.amazon.com/rds/) Amazon RDS makes it easy to set up, operate, and scale a relational database in the cloud. ",
    "url": "http://aws.amazon.com/rds/"
  },
  {
    "name": "[Crate.IO] (https://crate.io/) Scalable SQL database with the NOSQL goodies.",
    "url": "https://crate.io/"
  },
  {
    "name": "[Redis] (http://redis.io/) An open source, BSD licensed, advanced key-value cache and store.",
    "url": "http://redis.io/"
  },
  {
    "name": "[Riak] (https://docs.basho.com/riak/latest/) A distributed database designed to deliver maximum data availability by distributing data across multiple servers.",
    "url": "https://docs.basho.com/riak/latest/"
  },
  {
    "name": "[AWS DynamoDB] (http://aws.amazon.com/dynamodb/) A fast and flexible NoSQL database service for all applications that need consistent, single-digit millisecond latency at any scale.",
    "url": "http://aws.amazon.com/dynamodb/"
  },
  {
    "name": "HyperDex HyperDex is a scalable, searchable key-value store",
    "url": "https://github.com/rescrv/HyperDex"
  },
  {
    "name": "SSDB A high performance NoSQL database supporting many data structures, an alternative to Redis",
    "url": "http://ssdb.io"
  },
  {
    "name": "Kyoto Tycoon Kyoto Tycoon is a lightweight network server on top of the Kyoto Cabinet key-value database, built for high-performance and concurrency",
    "url": "https://github.com/sapo/kyoto"
  },
  {
    "name": "IonDB A key-value store for microcontroller and IoT applications",
    "url": "https://github.com/iondbproject/iondb"
  },
  {
    "name": "[Cassandra] (http://cassandra.apache.org/) The right choice when you need scalability and high availability without compromising performance.\n[Cassandra Calculator] (http://www.ecyrd.com/cassandracalculator/) This simple form allows you to try out different values for your Apache Cassandra cluster and see what the impact is for your application.\nCCM A script to easily create and destroy an Apache Cassandra cluster on localhost\n\n",
    "url": "http://cassandra.apache.org/"
  },
  {
    "name": "[Cassandra Calculator] (http://www.ecyrd.com/cassandracalculator/) This simple form allows you to try out different values for your Apache Cassandra cluster and see what the impact is for your application.",
    "url": "http://www.ecyrd.com/cassandracalculator/"
  },
  {
    "name": "CCM A script to easily create and destroy an Apache Cassandra cluster on localhost",
    "url": "https://github.com/pcmanus/ccm"
  },
  {
    "name": "[HBase] (http://hbase.apache.org/) The Hadoop database, a distributed, scalable, big data store.",
    "url": "http://hbase.apache.org/"
  },
  {
    "name": "[Infobright] (http://www.infobright.org) Column oriented, open-source analytic database provides both speed and efficiency.  ",
    "url": "http://www.infobright.org"
  },
  {
    "name": "[AWS Redshift] (http://aws.amazon.com/redshift/) A fast, fully managed, petabyte-scale data warehouse that makes it simple and cost-effective to analyze all your data using your existing business intelligence tools.",
    "url": "http://aws.amazon.com/redshift/"
  },
  {
    "name": "FiloDB (https://github.com/tuplejump/FiloDB) Distributed. Columnar. Versioned. Streaming. SQL.",
    "url": "https://github.com/tuplejump/FiloDB"
  },
  {
    "name": "[MongoDB] (https://www.mongodb.org/) An open-source, document database designed for ease of development and scaling. ",
    "url": "https://www.mongodb.org/"
  },
  {
    "name": "Percona Server for MongoDB Percona Server for MongoDB® is a free, enhanced, fully compatible, open source, drop-in replacement for the MongoDB® Community Edition that includes enterprise-grade features and functionality.",
    "url": "https://www.percona.com/software/mongo-database/percona-server-for-mongodb"
  },
  {
    "name": "[Elasticsearch] (https://www.elastic.co/) Search & Analyze Data in Real Time.",
    "url": "https://www.elastic.co/"
  },
  {
    "name": "[Couchbase] (http://www.couchbase.com/) The highest performing NoSQL distributed database.",
    "url": "http://www.couchbase.com/"
  },
  {
    "name": "RethinkDB The open-source database for the realtime web.",
    "url": "http://rethinkdb.com/"
  },
  {
    "name": "[Neo4j] (http://neo4j.com/) The world’s leading graph database.",
    "url": "http://neo4j.com/"
  },
  {
    "name": "[OrientDB] (http://orientdb.com/orientdb/) 2nd Generation Distributed Graph Database with the flexibility of Documents in one product with an Open Source commercial friendly license.",
    "url": "http://orientdb.com/orientdb/"
  },
  {
    "name": "[ArangoDB] (https://www.arangodb.com/) A distributed free and open-source database with a flexible data model for documents, graphs, and key-values. ",
    "url": "https://www.arangodb.com/"
  },
  {
    "name": "[Titan] (http://thinkaurelius.github.io/titan/) A scalable graph database optimized for storing and querying graphs containing hundreds of billions of vertices and edges distributed across a multi-machine cluster.",
    "url": "http://thinkaurelius.github.io/titan/"
  },
  {
    "name": "FlockDB A distributed, fault-tolerant graph database by Twitter.",
    "url": "https://github.com/twitter/flockdb"
  },
  {
    "name": "DAtomic The fully transactional, cloud-ready, distributed database.",
    "url": "http://www.datomic.com"
  },
  {
    "name": "Apache Geode An open source, distributed, in-memory database for scale-out applications.",
    "url": "http://geode.incubator.apache.org"
  },
  {
    "name": "InfluxDB Scalable datastore for metrics, events, and real-time analytics.",
    "url": "https://github.com/influxdb/influxdb"
  },
  {
    "name": "OpenTSDB A scalable, distributed Time Series Database.",
    "url": "https://github.com/OpenTSDB/opentsdb"
  },
  {
    "name": "kairosdb Fast scalable time series database.",
    "url": "https://github.com/kairosdb/kairosdb"
  },
  {
    "name": "[Heroic] (https://github.com/spotify/heroic) A scalable time series database based on Cassandra and Elasticsearch, by Spotify",
    "url": "https://github.com/spotify/heroic"
  },
  {
    "name": "Tarantool Tarantool is an in-memory database and application server.",
    "url": "https://github.com/tarantool/tarantool/"
  },
  {
    "name": "GreenPlum The Greenplum Database (GPDB) is an advanced, fully featured, open source data warehouse. It provides powerful and rapid analytics on petabyte scale data volumes.",
    "url": "https://github.com/greenplum-db/gpdb"
  },
  {
    "name": "cayley An open-source graph database. Google.Data Ingestion\n",
    "url": "https://github.com/google/cayley"
  },
  {
    "name": "[Kafka] (http://kafka.apache.org/) Publish-subscribe messaging rethought as a distributed commit log.\nCamus LinkedIn's Kafka to HDFS pipeline.\nBottledWater Change data capture from PostgreSQL into Kafka\nkafkat Simplified command-line administration for Kafka brokers\nkafkacat Generic command line non-JVM Apache Kafka producer and consumer\npg-kafka A PostgreSQL extension to produce messages to Apache Kafka\nlibrdkafka The Apache Kafka C/C++ library\nkafka-docker Kafka in Docker\nkafka-manager A tool for managing Apache Kafka\nkafka-node Node.js client for Apache Kafka 0.8\n[Secor] (https://github.com/pinterest/secor) Pinterest's Kafka to S3 distributed consumer\n\n",
    "url": "http://kafka.apache.org/"
  },
  {
    "name": "Camus LinkedIn's Kafka to HDFS pipeline.",
    "url": "https://github.com/linkedin/camus"
  },
  {
    "name": "BottledWater Change data capture from PostgreSQL into Kafka",
    "url": "https://github.com/confluentinc/bottledwater-pg"
  },
  {
    "name": "kafkat Simplified command-line administration for Kafka brokers",
    "url": "https://github.com/airbnb/kafkat"
  },
  {
    "name": "kafkacat Generic command line non-JVM Apache Kafka producer and consumer",
    "url": "https://github.com/edenhill/kafkacat"
  },
  {
    "name": "pg-kafka A PostgreSQL extension to produce messages to Apache Kafka",
    "url": "https://github.com/xstevens/pg_kafka"
  },
  {
    "name": "librdkafka The Apache Kafka C/C++ library",
    "url": "https://github.com/edenhill/librdkafka"
  },
  {
    "name": "kafka-docker Kafka in Docker",
    "url": "https://github.com/wurstmeister/kafka-docker"
  },
  {
    "name": "kafka-manager A tool for managing Apache Kafka",
    "url": "https://github.com/yahoo/kafka-manager"
  },
  {
    "name": "kafka-node Node.js client for Apache Kafka 0.8",
    "url": "https://github.com/SOHU-Co/kafka-node"
  },
  {
    "name": "[Secor] (https://github.com/pinterest/secor) Pinterest's Kafka to S3 distributed consumer",
    "url": "https://github.com/pinterest/secor"
  },
  {
    "name": "[AWS Kinesis] (http://aws.amazon.com/kinesis/) A fully managed, cloud-based service for real-time data processing over large, distributed data streams.",
    "url": "http://aws.amazon.com/kinesis/"
  },
  {
    "name": "RabbitMQ Robust messaging for applications.",
    "url": "http://www.rabbitmq.com/"
  },
  {
    "name": "FluentD An open source data collector for unified logging layer.",
    "url": "http://www.fluentd.org"
  },
  {
    "name": "Apache Scoop A tool designed for efficiently transferring bulk data between Apache Hadoop and structured datastores such as relational databases.",
    "url": "https://sqoop.apache.org"
  },
  {
    "name": "Heka Data Acquisition and Processing Made Easy",
    "url": "https://github.com/mozilla-services/heka"
  },
  {
    "name": "Gobblin Universal data ingestion framework for Hadoop from Linkedin",
    "url": "https://github.com/linkedin/gobblin"
  },
  {
    "name": "[HDFS] (https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html)\nSnakebite A pure python HDFS client\n\n",
    "url": "https://hadoop.apache.org/docs/r1.2.1/hdfs_design.html"
  },
  {
    "name": "Snakebite A pure python HDFS client",
    "url": "https://github.com/spotify/snakebite"
  },
  {
    "name": "[AWS S3] (http://aws.amazon.com/s3/)\n[smart_open] (https://github.com/piskvorky/smart_open) Utils for streaming large files (S3, HDFS, gzip, bz2)\n\n",
    "url": "http://aws.amazon.com/s3/"
  },
  {
    "name": "[smart_open] (https://github.com/piskvorky/smart_open) Utils for streaming large files (S3, HDFS, gzip, bz2)",
    "url": "https://github.com/piskvorky/smart_open"
  },
  {
    "name": "[Tachyon] (http://tachyon-project.org/) Tachyon is a memory-centric distributed storage system enabling reliable data sharing at memory-speed across cluster frameworks, such as Spark and MapReduce",
    "url": "http://tachyon-project.org/"
  },
  {
    "name": "CEPH Ceph is a unified, distributed storage system designed for excellent performance, reliability and scalability",
    "url": "http://ceph.com/"
  },
  {
    "name": "OrangeFS Orange File System is a branch of the Parallel Virtual File System",
    "url": "http://www.orangefs.org/"
  },
  {
    "name": "SnackFS SnackFS is our bite-sized, lightweight HDFS compatible FileSystem built over Cassandra",
    "url": "https://github.com/tuplejump/snackfs-release"
  },
  {
    "name": "GlusterFS Gluster Filesystem",
    "url": "http://www.gluster.org/"
  },
  {
    "name": "XtreemFS fault-tolerant distributed file system for all storage needs",
    "url": "http://www.xtreemfs.org/"
  },
  {
    "name": "SeaweedFS Seaweed-FS is a simple and highly scalable distributed file system. There are two objectives: to store billions of files! to serve the files fast! Instead of supporting full POSIX file system semantics, Seaweed-FS choose to implement only a key~file mapping. Similar to the word \"NoSQL\", you can call it as \"NoFS\".",
    "url": "https://github.com/chrislusf/seaweedfs"
  },
  {
    "name": "S3QL S3QL is a file system that stores all its data online using storage services like Google Storage, Amazon S3, or OpenStack.",
    "url": "https://bitbucket.org/nikratio/s3ql"
  },
  {
    "name": "Apache Avro Apache Avro™ is a data serialization system",
    "url": "https://avro.apache.org"
  },
  {
    "name": "Apache Parquet Apache Parquet is a columnar storage format available to any project in the Hadoop ecosystem, regardless of the choice of data processing framework, data model or programming language.\nSnappy A fast compressor/decompressor. Used with Parquet\nPigZ A parallel implementation of gzip for modern\nmulti-processor, multi-core machines\n\n",
    "url": "https://parquet.apache.org"
  },
  {
    "name": "Snappy A fast compressor/decompressor. Used with Parquet",
    "url": "https://github.com/google/snappy"
  },
  {
    "name": "PigZ A parallel implementation of gzip for modern\nmulti-processor, multi-core machines",
    "url": "http://zlib.net/pigz/"
  },
  {
    "name": "Apache ORC The smallest, fastest columnar storage for Hadoop workloads ",
    "url": "https://orc.apache.org/"
  },
  {
    "name": "Apache Thrift The Apache Thrift software framework, for scalable cross-language services development",
    "url": "https://thrift.apache.org"
  },
  {
    "name": "ProtoBuf Protocol Buffers",
    "url": "https://github.com/google/protobuf",
    "description": "Google's data interchange format"
  },
  {
    "name": "SequenceFile SequenceFile is a flat file consisting of binary key/value pairs. It is extensively used in MapReduce as input/output formats",
    "url": "http://wiki.apache.org/hadoop/SequenceFile"
  },
  {
    "name": "Kryo Kryo is a fast and efficient object graph serialization framework for Java",
    "url": "https://github.com/EsotericSoftware/kryo"
  },
  {
    "name": "Spark Streaming Spark Streaming makes it easy to build scalable fault-tolerant streaming applications.",
    "url": "https://spark.apache.org/streaming/"
  },
  {
    "name": "Apache Flink Apache Flink is a streaming dataflow engine that provides data distribution, communication, and fault tolerance for distributed computations over data streams.",
    "url": "https://flink.apache.org/"
  },
  {
    "name": "Apache Storm Apache Storm is a free and open source distributed realtime computation system",
    "url": "https://storm.apache.org"
  },
  {
    "name": "Apache Samza Apache Samza is a distributed stream processing framework",
    "url": "https://samza.apache.org"
  },
  {
    "name": "Apache NiFi is an easy to use, powerful, and reliable system to process and distribute data",
    "url": "http://nifi.apache.org/"
  },
  {
    "name": "VoltDB",
    "url": "https://voltdb.com/"
  },
  {
    "name": "PipelineDB The Streaming SQL Database https://www.pipelinedb.com",
    "url": "https://github.com/pipelinedb/pipelinedb"
  },
  {
    "name": "[Hadoop MapReduce] (http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html) Hadoop MapReduce is a software framework for easily writing applications which process vast amounts of data (multi-terabyte data-sets) in-parallel on large clusters (thousands of nodes) of commodity hardware in a reliable, fault-tolerant manner",
    "url": "http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html"
  },
  {
    "name": "[Spark] (https://spark.apache.org/)\nSpark Packages A community index of packages for Apache Spark\nDeep Spark Connecting Apache Spark with different data stores \nSpark RDD API Examples by Zhen He\nLivy Livy, the REST Spark Server\n\n",
    "url": "https://spark.apache.org/"
  },
  {
    "name": "Spark Packages A community index of packages for Apache Spark",
    "url": "http://spark-packages.org"
  },
  {
    "name": "Deep Spark Connecting Apache Spark with different data stores ",
    "url": "https://github.com/Stratio/deep-spark"
  },
  {
    "name": "Spark RDD API Examples by Zhen He",
    "url": "http://homepage.cs.latrobe.edu.au/zhe/ZhenHeSparkRDDAPIExamples.html"
  },
  {
    "name": "Livy Livy, the REST Spark Server",
    "url": "https://github.com/cloudera/hue/tree/master/apps/spark/java#welcome-to-livy-the-rest-spark-server"
  },
  {
    "name": "[AWS EMR] (http://aws.amazon.com/elasticmapreduce/) A web service that makes it easy to quickly and cost-effectively process vast amounts of data.",
    "url": "http://aws.amazon.com/elasticmapreduce/"
  },
  {
    "name": "Flink An open source platform for scalable batch and stream data processing.",
    "url": "https://flink.apache.org/"
  },
  {
    "name": "[Tez] (https://tez.apache.org/) An application framework which allows for a complex directed-acyclic-graph of tasks for processing data.",
    "url": "https://tez.apache.org/"
  },
  {
    "name": "[H2O] (http://h2o.ai/) Fast scalable machine learning API for smarter applications.",
    "url": "http://h2o.ai/"
  },
  {
    "name": "[Mahout] (http://mahout.apache.org/) An environment for quickly creating scalable performant machine learning applications.",
    "url": "http://mahout.apache.org/"
  },
  {
    "name": "[Spark MLlib] (https://spark.apache.org/docs/1.2.1/mllib-guide.html) Spark’s scalable machine learning library consisting of common learning algorithms and utilities, including classification, regression, clustering, collaborative filtering, dimensionality reduction, as well as underlying optimization primitives.",
    "url": "https://spark.apache.org/docs/1.2.1/mllib-guide.html"
  },
  {
    "name": "[GraphLab Create] (https://dato.com/products/create/) A machine learning platform that enables data scientists and app developers to easily create intelligent apps at scale.",
    "url": "https://dato.com/products/create/"
  },
  {
    "name": "[Giraph] (http://giraph.apache.org/) An iterative graph processing system built for high scalability. ",
    "url": "http://giraph.apache.org/"
  },
  {
    "name": "[Spark GraphX] (https://spark.apache.org/graphx/) Apache Spark's API for graphs and graph-parallel computation. ",
    "url": "https://spark.apache.org/graphx/"
  },
  {
    "name": "[Presto] (https://prestodb.io/docs/current/index.html) A distributed SQL query engine designed to query large data sets distributed over one or more heterogeneous data sources.",
    "url": "https://prestodb.io/docs/current/index.html"
  },
  {
    "name": "[Hive] (http://hive.apache.org) Data warehouse software facilitates querying and managing large datasets residing in distributed storage. \nHivemall Scalable machine learning library for Hive/Hadoop.\n[PyHive] (https://github.com/dropbox/PyHive) Python interface to Hive and Presto.\n\n",
    "url": "http://hive.apache.org"
  },
  {
    "name": "Hivemall Scalable machine learning library for Hive/Hadoop.",
    "url": "https://github.com/myui/hivemall"
  },
  {
    "name": "[PyHive] (https://github.com/dropbox/PyHive) Python interface to Hive and Presto.",
    "url": "https://github.com/dropbox/PyHive"
  },
  {
    "name": "[Drill] (https://drill.apache.org/) Schema-free SQL Query Engine for Hadoop, NoSQL and Cloud Storage.",
    "url": "https://drill.apache.org/"
  },
  {
    "name": "[Highcharts] (http://www.highcharts.com/) A charting library written in pure JavaScript, offering an easy way of adding interactive charts to your web site or web application.",
    "url": "http://www.highcharts.com/"
  },
  {
    "name": "ZingChart Fast JavaScript charts for any data set.",
    "url": "http://www.zingchart.com/"
  },
  {
    "name": "C3.js D3-based reusable chart library.",
    "url": "http://c3js.org"
  },
  {
    "name": "[D3.js] (http://d3js.org/) A JavaScript library for manipulating documents based on data.\n[D3Plus] (http://d3plus.org) D3's simplier, easier to use cousin. Mostly predefined templates that you can just plug data in.\n\n",
    "url": "http://d3js.org/"
  },
  {
    "name": "[D3Plus] (http://d3plus.org) D3's simplier, easier to use cousin. Mostly predefined templates that you can just plug data in.",
    "url": "http://d3plus.org"
  },
  {
    "name": "SmoothieCharts A JavaScript Charting Library for Streaming Data.",
    "url": "http://smoothiecharts.org"
  },
  {
    "name": "PyXley Python helpers for building dashboards using Flask and React",
    "url": "https://github.com/stitchfix/pyxley"
  },
  {
    "name": "[Luigi] (https://github.com/spotify/luigi) Luigi is a Python module that helps you build complex pipelines of batch jobs.\nCronQ An application cron-like system. Used w/Luige \n\n",
    "url": "https://github.com/spotify/luigi"
  },
  {
    "name": "CronQ An application cron-like system. Used w/Luige ",
    "url": "https://github.com/seatgeek/cronq"
  },
  {
    "name": "[Cascading] (http://www.cascading.org/) Java based application development platform.",
    "url": "http://www.cascading.org/"
  },
  {
    "name": "[Airflow] (https://github.com/airbnb/airflow) Airflow is a system to programmaticaly author, schedule and monitor data pipelines.",
    "url": "https://github.com/airbnb/airflow"
  },
  {
    "name": "[Azkaban] (https://azkaban.github.io/) Azkaban is a batch workflow job scheduler created at LinkedIn to run Hadoop jobs. Azkaban resolves the ordering through job dependencies and provides an easy to use web user interface to maintain and track your workflows. ",
    "url": "https://azkaban.github.io/"
  },
  {
    "name": "Oozie Oozie is a workflow scheduler system to manage Apache Hadoop jobs",
    "url": "http://oozie.apache.org/"
  },
  {
    "name": "docker-logstash A highly configurable logstash (1.4.4) docker image running Elasticsearch (1.7.0) and Kibana (3.1.2).",
    "url": "https://github.com/pblittle/docker-logstash"
  },
  {
    "name": "elasticsearch-jdbc JDBC importer for Elasticsearch",
    "url": "https://github.com/jprante/elasticsearch-jdbc"
  },
  {
    "name": "ZomboDB Postgres Extension that allows creating an index backed by Elasticsearch",
    "url": "https://github.com/zombodb/zombodb"
  },
  {
    "name": "Gockerize Package golang service into minimal docker containers",
    "url": "https://github.com/aerofs/gockerize"
  },
  {
    "name": "Flocker Easily manage Docker containers & their data",
    "url": "https://github.com/ClusterHQ/flocker"
  },
  {
    "name": "Rancher RancherOS is a 20mb Linux distro that runs the entire OS as Docker containers",
    "url": "http://rancher.com/rancher-os/"
  },
  {
    "name": "Kontena Application Containers for Masses",
    "url": "http://www.kontena.io/"
  },
  {
    "name": "Weave Weaving Docker containers into applications http://weave.works",
    "url": "https://github.com/weaveworks/weave"
  },
  {
    "name": "Zodiac A lightweight tool for easy deployment and rollback of dockerized applications",
    "url": "https://github.com/CenturyLinkLabs/zodiac"
  },
  {
    "name": "cAdvisor Analyzes resource usage and performance characteristics of running containers",
    "url": "https://github.com/google/cadvisor"
  },
  {
    "name": "Micro S3 persistence Docker microservice for saving/restoring volume data to S3",
    "url": "https://github.com/shinymayhem/micro-s3-persistence"
  },
  {
    "name": "Dockup Docker image to backup/restore your Docker container volumes to AWS S3",
    "url": "https://github.com/tutumcloud/dockup"
  },
  {
    "name": "Rocker-compose Docker composition tool with idempotency features for deploying apps composed of multiple containers.",
    "url": "https://github.com/grammarly/rocker-compose"
  },
  {
    "name": "Nomad Nomad is a cluster manager, designed for both long lived services and short lived batch processing workloads",
    "url": "https://github.com/hashicorp/nomad"
  },
  {
    "name": "Instagram Realtime Real-time photo updates provide your application with instant notifications of new photos as they are posted on Instagram.",
    "url": "https://instagram.com/developer/realtime/"
  },
  {
    "name": "Twitter Realtime The Streaming APIs give developers low latency access to Twitter’s global stream of Tweet data.",
    "url": "https://dev.twitter.com/streaming/overview"
  },
  {
    "name": "Firebase Realtime Airport delays, Parking,  Cryptocurrencies, Earthquakes, Transit, Weather",
    "url": "https://www.firebase.com/docs/open-data/"
  },
  {
    "name": "Eventsim Event data simulator. Generates a stream of pseudo-random events from a set of users, designed to simulate web traffic.",
    "url": "https://github.com/Interana/eventsim"
  },
  {
    "name": "[Reddit] (https://www.reddit.com/r/datasets/comments/3mk1vg/realtime_data_is_available_including_comments/) Real-time data is available including comments, submissions and links posted to reddit",
    "url": "https://www.reddit.com/r/datasets/comments/3mk1vg/realtime_data_is_available_including_comments/"
  },
  {
    "name": "[GitHub Archive] (https://www.githubarchive.org/) GitHub's public timeline since 2011, updated every hour",
    "url": "https://www.githubarchive.org/"
  },
  {
    "name": "[Common Crawl] (https://commoncrawl.org/) Open source repository of web crawl data",
    "url": "https://commoncrawl.org/"
  },
  {
    "name": "[Wikipedia] (https://dumps.wikimedia.org/enwiki/latest/) Wikipedia's complete copy of all wikis, in the form of wikitext source and metadata embedded in XML. A number of raw database tables in SQL form are also available.",
    "url": "https://dumps.wikimedia.org/enwiki/latest/"
  },
  {
    "name": "Prometheus.io An open-source service monitoring system and time series database",
    "url": "https://github.com/prometheus/prometheus"
  },
  {
    "name": "HAProxy Exporter Simple server that scrapes HAProxy stats and exports them via HTTP for Prometheus consumption",
    "url": "https://github.com/prometheus/haproxy_exporter"
  }
]
